{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs==2.4.3 (from -r requirements.txt (line 1))\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiohttp==3.10.10 (from -r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: aiosignal==1.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.3.1)\n",
      "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting anyio==4.6.2.post1 (from -r requirements.txt (line 5))\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting appnope==0.1.4 (from -r requirements.txt (line 6))\n",
      "  Downloading appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: attrs==24.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (24.2.0)\n",
      "Requirement already satisfied: cachetools==5.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (5.5.0)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2024.8.30)\n",
      "Collecting charset-normalizer==3.4.0 (from -r requirements.txt (line 11))\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: cloudpickle==3.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: comm==0.2.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.2.2)\n",
      "Collecting dataclasses-json==0.6.7 (from -r requirements.txt (line 14))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting debugpy==1.8.7 (from -r requirements.txt (line 15))\n",
      "  Downloading debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (5.1.1)\n",
      "Requirement already satisfied: Deprecated==1.2.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.2.14)\n",
      "Requirement already satisfied: docstring_parser==0.16 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (0.16)\n",
      "Requirement already satisfied: executing==2.1.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (2.1.0)\n",
      "Collecting frozenlist==1.5.0 (from -r requirements.txt (line 20))\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from -r requirements.txt (line 21))\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core==2.22.0 (from -r requirements.txt (line 22))\n",
      "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-api-python-client==2.151.0 (from -r requirements.txt (line 23))\n",
      "  Downloading google_api_python_client-2.151.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth==2.35.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (2.35.0)\n",
      "Requirement already satisfied: google-auth-httplib2==0.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (0.2.0)\n",
      "Collecting google-cloud-aiplatform==1.71.1 (from -r requirements.txt (line 26))\n",
      "  Downloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-cloud-bigquery==3.26.0 (from -r requirements.txt (line 27))\n",
      "  Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: google-cloud-core==2.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (2.4.1)\n",
      "Collecting google-cloud-discoveryengine==0.13.3 (from -r requirements.txt (line 29))\n",
      "  Downloading google_cloud_discoveryengine-0.13.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-resource-manager==1.13.0 (from -r requirements.txt (line 30))\n",
      "  Downloading google_cloud_resource_manager-1.13.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-storage==2.18.2 (from -r requirements.txt (line 31))\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-trace==1.14.0 (from -r requirements.txt (line 32))\n",
      "  Downloading google_cloud_trace-1.14.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: google-crc32c==1.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 33)) (1.6.0)\n",
      "Collecting google-generativeai==0.8.3 (from -r requirements.txt (line 34))\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: google-resumable-media==2.7.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (2.7.2)\n",
      "Requirement already satisfied: googleapis-common-protos==1.65.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 36)) (1.65.0)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (3.1.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1==0.13.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (0.13.1)\n",
      "Collecting grpcio==1.67.1 (from -r requirements.txt (line 39))\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status==1.67.1 (from -r requirements.txt (line 40))\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: h11==0.14.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 41)) (0.14.0)\n",
      "Collecting httpcore==1.0.6 (from -r requirements.txt (line 42))\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: httplib2==0.22.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 43)) (0.22.0)\n",
      "Collecting httpx==0.27.2 (from -r requirements.txt (line 44))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse==0.4.0 (from -r requirements.txt (line 45))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting idna==3.10 (from -r requirements.txt (line 46))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting importlib_metadata==8.5.0 (from -r requirements.txt (line 47))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 48)) (6.29.5)\n",
      "Collecting ipython==8.29.0 (from -r requirements.txt (line 49))\n",
      "  Downloading ipython-8.29.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 50)) (8.1.5)\n",
      "Requirement already satisfied: jedi==0.19.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 51)) (0.19.1)\n",
      "Requirement already satisfied: jsonpatch==1.33 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 52)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 53)) (3.0.0)\n",
      "Collecting jupyter_client==8.6.3 (from -r requirements.txt (line 54))\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 55)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 56)) (3.0.13)\n",
      "Collecting langchain==0.2.17 (from -r requirements.txt (line 57))\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.2.18 (from -r requirements.txt (line 58))\n",
      "  Downloading langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-core==0.2.43 (from -r requirements.txt (line 59))\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-google-community==1.0.8 (from -r requirements.txt (line 60))\n",
      "  Downloading langchain_google_community-1.0.8-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-google-vertexai==1.0.10 (from -r requirements.txt (line 61))\n",
      "  Downloading langchain_google_vertexai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-text-splitters==0.2.4 (from -r requirements.txt (line 62))\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith==0.1.140 (from -r requirements.txt (line 63))\n",
      "  Downloading langsmith-0.1.140-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting marshmallow==3.23.1 (from -r requirements.txt (line 64))\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 65)) (0.1.7)\n",
      "Requirement already satisfied: multidict==6.1.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 66)) (6.1.0)\n",
      "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 67))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 68)) (1.6.0)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 69))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting openinference-instrumentation==0.1.18 (from -r requirements.txt (line 70))\n",
      "  Downloading openinference_instrumentation-0.1.18-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting openinference-instrumentation-langchain==0.1.29 (from -r requirements.txt (line 71))\n",
      "  Downloading openinference_instrumentation_langchain-0.1.29-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting openinference-semantic-conventions==0.1.12 (from -r requirements.txt (line 72))\n",
      "  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-api==1.28.0 (from -r requirements.txt (line 73))\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-gcp-trace==1.7.0 (from -r requirements.txt (line 74))\n",
      "  Downloading opentelemetry_exporter_gcp_trace-1.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from -r requirements.txt (line 75))\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-resourcedetector-gcp==1.7.0a0 (from -r requirements.txt (line 76))\n",
      "  Downloading opentelemetry_resourcedetector_gcp-1.7.0a0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk==1.28.0 (from -r requirements.txt (line 77))\n",
      "  Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from -r requirements.txt (line 78))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting orjson==3.10.6 (from -r requirements.txt (line 79))\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: packaging==24.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 80)) (24.1)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 81))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 83)) (4.9.0)\n",
      "Collecting platformdirs==4.3.6 (from -r requirements.txt (line 84))\n",
      "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting prompt_toolkit==3.0.48 (from -r requirements.txt (line 85))\n",
      "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting propcache==0.2.0 (from -r requirements.txt (line 86))\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting proto-plus==1.25.0 (from -r requirements.txt (line 87))\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf==5.28.3 (from -r requirements.txt (line 88))\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting psutil==6.1.0 (from -r requirements.txt (line 89))\n",
      "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 90)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 91)) (0.2.3)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 92)) (0.6.1)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 93)) (0.4.1)\n",
      "Collecting pydantic==2.7.4 (from -r requirements.txt (line 94))\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "Collecting pydantic_core==2.18.4 (from -r requirements.txt (line 95))\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 96)) (2.18.0)\n",
      "Collecting pyparsing==3.2.0 (from -r requirements.txt (line 97))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting PyPDF2==3.0.1 (from -r requirements.txt (line 98))\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 99)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 100)) (2024.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 101)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 102)) (26.2.0)\n",
      "Collecting regex==2024.9.11 (from -r requirements.txt (line 103))\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests==2.32.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 104)) (2.32.3)\n",
      "Collecting requests-toolbelt==1.0.0 (from -r requirements.txt (line 105))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: rsa==4.9 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 106)) (4.9)\n",
      "Requirement already satisfied: shapely==2.0.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 107)) (2.0.6)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 108)) (1.16.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 109)) (1.3.1)\n",
      "Collecting SQLAlchemy==2.0.36 (from -r requirements.txt (line 110))\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 111)) (0.6.3)\n",
      "Collecting tenacity==8.3.0 (from -r requirements.txt (line 112))\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken==0.8.0 (from -r requirements.txt (line 113))\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tornado==6.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 114)) (6.4.1)\n",
      "Collecting tqdm==4.66.6 (from -r requirements.txt (line 115))\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 116)) (5.14.3)\n",
      "Collecting typing-inspect==0.9.0 (from -r requirements.txt (line 117))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 118)) (4.12.2)\n",
      "Collecting tzdata==2024.2 (from -r requirements.txt (line 119))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting uritemplate==4.1.1 (from -r requirements.txt (line 120))\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting urllib3==2.2.3 (from -r requirements.txt (line 121))\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 122)) (0.2.13)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 123)) (4.0.13)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 124)) (1.16.0)\n",
      "Collecting yarl==1.17.1 (from -r requirements.txt (line 125))\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Requirement already satisfied: zipp==3.20.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 126)) (3.20.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp==3.10.10->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio==4.6.2.post1->-r requirements.txt (line 5)) (1.2.2)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'langsmith' candidate (version 0.1.140 at https://files.pythonhosted.org/packages/60/e6/9487d1bfea455424ad4dfb498bc5fa983c00a73915b529e97573c7576d35/langsmith-0.1.140-py3-none-any.whl (from https://pypi.org/simple/langsmith/) (requires-python:<4.0,>=3.8.1))\n",
      "Reason for being yanked: Imported six in a critical path\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.22.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_api_python_client-2.151.0-py2.py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
      "Downloading google_cloud_discoveryengine-0.13.3-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.13.0-py2.py3-none-any.whl (359 kB)\n",
      "Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Downloading google_cloud_trace-1.14.0-py2.py3-none-any.whl (94 kB)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading ipython-8.29.0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.9/819.9 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "Downloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.2.18-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Downloading langchain_google_community-1.0.8-py3-none-any.whl (75 kB)\n",
      "Downloading langchain_google_vertexai-1.0.10-py3-none-any.whl (86 kB)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.140-py3-none-any.whl (304 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m153.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openinference_instrumentation-0.1.18-py3-none-any.whl (14 kB)\n",
      "Downloading openinference_instrumentation_langchain-0.1.29-py3-none-any.whl (17 kB)\n",
      "Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\n",
      "Downloading opentelemetry_api-1.28.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_gcp_trace-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_resourcedetector_gcp-1.7.0a0-py3-none-any.whl (20 kB)\n",
      "Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl (159 kB)\n",
      "Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m146.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m142.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m143.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "Installing collected packages: urllib3, uritemplate, tzdata, tqdm, tenacity, SQLAlchemy, regex, PyPDF2, pyparsing, pydantic_core, psutil, protobuf, propcache, prompt_toolkit, platformdirs, orjson, openinference-semantic-conventions, numpy, mypy-extensions, marshmallow, importlib_metadata, idna, httpx-sse, httpcore, grpcio, frozenlist, debugpy, charset-normalizer, appnope, annotated-types, aiohappyeyeballs, yarl, typing-inspect, pydantic, proto-plus, pandas, opentelemetry-api, anyio, tiktoken, requests-toolbelt, opentelemetry-semantic-conventions, jupyter_client, ipython, httpx, grpcio-status, google-api-core, dataclasses-json, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation, langsmith, google-api-python-client, opentelemetry-resourcedetector-gcp, openinference-instrumentation, langchain-core, google-cloud-trace, google-cloud-storage, google-cloud-resource-manager, google-cloud-discoveryengine, google-cloud-bigquery, google-ai-generativelanguage, opentelemetry-exporter-gcp-trace, openinference-instrumentation-langchain, langchain-text-splitters, google-generativeai, google-cloud-aiplatform, langchain-google-vertexai, langchain, langchain-community, langchain-google-community\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.20\n",
      "    Uninstalling urllib3-1.26.20:\n",
      "      Successfully uninstalled urllib3-1.26.20\n",
      "  Attempting uninstall: uritemplate\n",
      "    Found existing installation: uritemplate 3.0.1\n",
      "    Uninstalling uritemplate-3.0.1:\n",
      "      Successfully uninstalled uritemplate-3.0.1\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.5\n",
      "    Uninstalling tqdm-4.66.5:\n",
      "      Successfully uninstalled tqdm-4.66.5\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.35\n",
      "    Uninstalling SQLAlchemy-2.0.35:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.35\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.4\n",
      "    Uninstalling pyparsing-3.1.4:\n",
      "      Successfully uninstalled pyparsing-3.1.4\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~yparsing'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.3\n",
      "    Uninstalling psutil-5.9.3:\n",
      "      Successfully uninstalled psutil-5.9.3\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~sutil'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~rotobuf'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: prompt_toolkit\n",
      "    Found existing installation: prompt_toolkit 3.0.47\n",
      "    Uninstalling prompt_toolkit-3.0.47:\n",
      "      Successfully uninstalled prompt_toolkit-3.0.47\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rompt_toolkit'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.2.2\n",
      "    Uninstalling platformdirs-4.2.2:\n",
      "      Successfully uninstalled platformdirs-4.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~umpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: importlib_metadata\n",
      "    Found existing installation: importlib_metadata 8.4.0\n",
      "    Uninstalling importlib_metadata-8.4.0:\n",
      "      Successfully uninstalled importlib_metadata-8.4.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~mportlib_metadata'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.8\n",
      "    Uninstalling idna-3.8:\n",
      "      Successfully uninstalled idna-3.8\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.66.1\n",
      "    Uninstalling grpcio-1.66.1:\n",
      "      Successfully uninstalled grpcio-1.66.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.1\n",
      "    Uninstalling frozenlist-1.4.1:\n",
      "      Successfully uninstalled frozenlist-1.4.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rozenlist'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.5\n",
      "    Uninstalling debugpy-1.8.5:\n",
      "      Successfully uninstalled debugpy-1.8.5\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.4.0\n",
      "    Uninstalling aiohappyeyeballs-2.4.0:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.4.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~iohappyeyeballs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.11.1\n",
      "    Uninstalling yarl-1.11.1:\n",
      "      Successfully uninstalled yarl-1.11.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~arl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.18\n",
      "    Uninstalling pydantic-1.10.18:\n",
      "      Successfully uninstalled pydantic-1.10.18\n",
      "  Attempting uninstall: proto-plus\n",
      "    Found existing installation: proto-plus 1.24.0\n",
      "    Uninstalling proto-plus-1.24.0:\n",
      "      Successfully uninstalled proto-plus-1.24.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~roto'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~andas'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.27.0\n",
      "    Uninstalling opentelemetry-api-1.27.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.27.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~ttributes'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~ontext'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~nvironment_variables'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~etrics'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~race'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~til'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.6.0\n",
      "    Uninstalling anyio-4.6.0:\n",
      "      Successfully uninstalled anyio-4.6.0\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.48b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.48b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.48b0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~emconv'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: jupyter_client\n",
      "    Found existing installation: jupyter_client 7.4.9\n",
      "    Uninstalling jupyter_client-7.4.9:\n",
      "      Successfully uninstalled jupyter_client-7.4.9\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.21.0\n",
      "    Uninstalling ipython-8.21.0:\n",
      "      Successfully uninstalled ipython-8.21.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~Python'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.48.2\n",
      "    Uninstalling grpcio-status-1.48.2:\n",
      "      Successfully uninstalled grpcio-status-1.48.2\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc_status'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~pi_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.10.5\n",
      "    Uninstalling aiohttp-3.10.5:\n",
      "      Successfully uninstalled aiohttp-3.10.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~iohttp'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.27.0\n",
      "    Uninstalling opentelemetry-sdk-1.27.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.27.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/opentelemetry/~dk'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.8.0\n",
      "    Uninstalling google-api-python-client-1.8.0:\n",
      "      Successfully uninstalled google-api-python-client-1.8.0\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~torage'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-cloud-resource-manager\n",
      "    Found existing installation: google-cloud-resource-manager 1.12.5\n",
      "    Uninstalling google-cloud-resource-manager-1.12.5:\n",
      "      Successfully uninstalled google-cloud-resource-manager-1.12.5\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.25.0\n",
      "    Uninstalling google-cloud-bigquery-3.25.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.25.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~igquery'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.67.1\n",
      "    Uninstalling google-cloud-aiplatform-1.67.1:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.67.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.151.0 which is incompatible.\n",
      "dataproc-jupyter-plugin 0.1.74 requires pydantic~=1.10.0, but you have pydantic 2.7.4 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 5.28.3 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.3 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.3 which is incompatible.\n",
      "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.27.0 requires opentelemetry-sdk~=1.27.0, but you have opentelemetry-sdk 1.28.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.27.0 requires opentelemetry-sdk~=1.27.0, but you have opentelemetry-sdk 1.28.0 which is incompatible.\n",
      "opentelemetry-proto 1.27.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.3 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.2.3 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyPDF2-3.0.1 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 annotated-types-0.7.0 anyio-4.6.2.post1 appnope-0.1.4 charset-normalizer-3.4.0 dataclasses-json-0.6.7 debugpy-1.8.7 frozenlist-1.5.0 google-ai-generativelanguage-0.6.10 google-api-core-2.22.0 google-api-python-client-2.151.0 google-cloud-aiplatform-1.71.1 google-cloud-bigquery-3.26.0 google-cloud-discoveryengine-0.13.3 google-cloud-resource-manager-1.13.0 google-cloud-storage-2.18.2 google-cloud-trace-1.14.0 google-generativeai-0.8.3 grpcio-1.67.1 grpcio-status-1.67.1 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 idna-3.10 importlib_metadata-8.5.0 ipython-8.29.0 jupyter_client-8.6.3 langchain-0.2.17 langchain-community-0.2.18 langchain-core-0.2.43 langchain-google-community-1.0.8 langchain-google-vertexai-1.0.10 langchain-text-splitters-0.2.4 langsmith-0.1.140 marshmallow-3.23.1 mypy-extensions-1.0.0 numpy-1.26.4 openinference-instrumentation-0.1.18 openinference-instrumentation-langchain-0.1.29 openinference-semantic-conventions-0.1.12 opentelemetry-api-1.28.0 opentelemetry-exporter-gcp-trace-1.7.0 opentelemetry-instrumentation-0.49b0 opentelemetry-resourcedetector-gcp-1.7.0a0 opentelemetry-sdk-1.28.0 opentelemetry-semantic-conventions-0.49b0 orjson-3.10.6 pandas-2.2.3 platformdirs-4.3.6 prompt_toolkit-3.0.48 propcache-0.2.0 proto-plus-1.25.0 protobuf-5.28.3 psutil-6.1.0 pydantic-2.7.4 pydantic_core-2.18.4 pyparsing-3.2.0 regex-2024.9.11 requests-toolbelt-1.0.0 tenacity-8.3.0 tiktoken-0.8.0 tqdm-4.66.6 typing-inspect-0.9.0 tzdata-2024.2 uritemplate-4.1.1 urllib3-2.2.3 yarl-1.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotenv\n",
      "  Downloading pydotenv-0.0.7.tar.gz (2.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pydotenv\n",
      "  Building wheel for pydotenv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pydotenv: filename=pydotenv-0.0.7-py3-none-any.whl size=2201 sha256=123783b43785f6983122190cde37937d39be3266b0ac2edb710805e2bab38c06\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ef/19/3d/c8a6ae3d77769e1743682d007d8d0da00bf587d00fe2820e68\n",
      "Successfully built pydotenv\n",
      "Installing collected packages: pydotenv\n",
      "Successfully installed pydotenv-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "genai.configure(api_key=os.environ[\"API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings( title, article ):\n",
    "    result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=article,\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=title)\n",
    "    return result['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/gdpr_cased_articles_with_recitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_recitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article1</td>\n",
       "      <td>Subject-matter and objectives</td>\n",
       "      <td>This Regulation lays down rules relating to th...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation applies to the processing of p...</td>\n",
       "      <td>14,15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                  article_title  \\\n",
       "0   article1  Subject-matter and objectives   \n",
       "1   article2                 Material scope   \n",
       "2   article2                 Material scope   \n",
       "3   article2                 Material scope   \n",
       "4   article2                 Material scope   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  This Regulation lays down rules relating to th...   \n",
       "1  This Regulation applies to the processing of p...   \n",
       "2  This Regulation does not apply to the processi...   \n",
       "3  This Regulation does not apply to the processi...   \n",
       "4  This Regulation does not apply to the processi...   \n",
       "\n",
       "                article_recitals  \n",
       "0  1,2,3,4,5,6,7,8,9,10,11,12,13  \n",
       "1                          14,15  \n",
       "2                             16  \n",
       "3                            NaN  \n",
       "4                             18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embeddings(df['article_title'][0],df['article_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject-matter and objectives\n"
     ]
    }
   ],
   "source": [
    "print(df['article_title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    if not string:\n",
    "        return 0\n",
    "    # Returns the number of tokens in a text string\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in range(len(df.index)):\n",
    "    title, text = df['article_title'][i], df['article_text'][i]\n",
    "    token_len = num_tokens_from_string(text)\n",
    "    temp = [title, text, token_len]\n",
    "    embedding = get_embeddings(title, text)\n",
    "    temp.append(embedding)\n",
    "    list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(list, columns=['article_title', 'article_text', 'article_tokens', 'article_text_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_tokens</th>\n",
       "      <th>article_text_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject-matter and objectives</td>\n",
       "      <td>This Regulation lays down rules relating to th...</td>\n",
       "      <td>86</td>\n",
       "      <td>[-0.07772678, 0.0103528565, 0.0082582515, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation applies to the processing of p...</td>\n",
       "      <td>45</td>\n",
       "      <td>[-0.05222351, 0.053586897, -0.03747398, -0.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.040194023, 0.017073363, -0.057278626, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>37</td>\n",
       "      <td>[-0.043380607, 0.019432526, -0.039794073, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.057984274, 0.0064719967, -0.05763235, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   article_title  \\\n",
       "0  Subject-matter and objectives   \n",
       "1                 Material scope   \n",
       "2                 Material scope   \n",
       "3                 Material scope   \n",
       "4                 Material scope   \n",
       "\n",
       "                                        article_text  article_tokens  \\\n",
       "0  This Regulation lays down rules relating to th...              86   \n",
       "1  This Regulation applies to the processing of p...              45   \n",
       "2  This Regulation does not apply to the processi...              27   \n",
       "3  This Regulation does not apply to the processi...              37   \n",
       "4  This Regulation does not apply to the processi...              27   \n",
       "\n",
       "                             article_text_embeddings  \n",
       "0  [-0.07772678, 0.0103528565, 0.0082582515, -0.0...  \n",
       "1  [-0.05222351, 0.053586897, -0.03747398, -0.035...  \n",
       "2  [-0.040194023, 0.017073363, -0.057278626, -0.0...  \n",
       "3  [-0.043380607, 0.019432526, -0.039794073, -0.0...  \n",
       "4  [-0.057984274, 0.0064719967, -0.05763235, -0.0...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(df, df_new, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_recitals</th>\n",
       "      <th>article_tokens</th>\n",
       "      <th>article_text_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article1</td>\n",
       "      <td>Subject-matter and objectives</td>\n",
       "      <td>This Regulation lays down rules relating to th...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13</td>\n",
       "      <td>86</td>\n",
       "      <td>[-0.07772678, 0.0103528565, 0.0082582515, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation applies to the processing of p...</td>\n",
       "      <td>14,15</td>\n",
       "      <td>45</td>\n",
       "      <td>[-0.05222351, 0.053586897, -0.03747398, -0.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.040194023, 0.017073363, -0.057278626, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>[-0.043380607, 0.019432526, -0.039794073, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article2</td>\n",
       "      <td>Material scope</td>\n",
       "      <td>This Regulation does not apply to the processi...</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.057984274, 0.0064719967, -0.05763235, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                  article_title  \\\n",
       "0   article1  Subject-matter and objectives   \n",
       "1   article2                 Material scope   \n",
       "2   article2                 Material scope   \n",
       "3   article2                 Material scope   \n",
       "4   article2                 Material scope   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  This Regulation lays down rules relating to th...   \n",
       "1  This Regulation applies to the processing of p...   \n",
       "2  This Regulation does not apply to the processi...   \n",
       "3  This Regulation does not apply to the processi...   \n",
       "4  This Regulation does not apply to the processi...   \n",
       "\n",
       "                article_recitals  article_tokens  \\\n",
       "0  1,2,3,4,5,6,7,8,9,10,11,12,13              86   \n",
       "1                          14,15              45   \n",
       "2                             16              27   \n",
       "3                            NaN              37   \n",
       "4                             18              27   \n",
       "\n",
       "                             article_text_embeddings  \n",
       "0  [-0.07772678, 0.0103528565, 0.0082582515, -0.0...  \n",
       "1  [-0.05222351, 0.053586897, -0.03747398, -0.035...  \n",
       "2  [-0.040194023, 0.017073363, -0.057278626, -0.0...  \n",
       "3  [-0.043380607, 0.019432526, -0.039794073, -0.0...  \n",
       "4  [-0.057984274, 0.0064719967, -0.05763235, -0.0...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('./data/gdpr_cased_articles_with_recitals_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dot_product(text_embedding, question_embedding=\"\"):\n",
    "    return np.dot(text_embedding, question_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embedding = get_embeddings(\"user input\", \"What are my rights as an Individual in EU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['distance'] = x.article_text_embeddings.apply(lambda p: get_dot_product(p, question_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_recitals</th>\n",
       "      <th>article_tokens</th>\n",
       "      <th>article_text_embeddings</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>article77</td>\n",
       "      <td>Right to lodge a complaint with a supervisory ...</td>\n",
       "      <td>Without prejudice to any other administrative ...</td>\n",
       "      <td>141</td>\n",
       "      <td>70</td>\n",
       "      <td>[-0.04318639, 0.009823787, 0.0013123561, -0.02...</td>\n",
       "      <td>0.760135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>article22</td>\n",
       "      <td>Automated individual decision-making, includin...</td>\n",
       "      <td>The data subject shall have the right not to b...</td>\n",
       "      <td>71,72</td>\n",
       "      <td>39</td>\n",
       "      <td>[-0.04324376, 0.015624178, 0.016327191, -0.046...</td>\n",
       "      <td>0.746726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>article78</td>\n",
       "      <td>Right to an effective judicial remedy against ...</td>\n",
       "      <td>Without prejudice to any other administrative ...</td>\n",
       "      <td>143</td>\n",
       "      <td>40</td>\n",
       "      <td>[-0.045312826, -0.0052126944, 0.026995184, -0....</td>\n",
       "      <td>0.735505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>article15</td>\n",
       "      <td>Right of access by the data subject</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>63,64</td>\n",
       "      <td>58</td>\n",
       "      <td>[-0.047044102, 0.01906889, 0.0070038955, -0.04...</td>\n",
       "      <td>0.733498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>article47</td>\n",
       "      <td>Binding corporate rules</td>\n",
       "      <td>The binding corporate rules shall specify at l...</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "      <td>[-0.04559353, 0.005038787, 0.028027346, -0.033...</td>\n",
       "      <td>0.725485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>article4</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>'group of undertakings' means a controlling un...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>[-0.026804209, 0.029797085, 0.0009110155, -0.0...</td>\n",
       "      <td>0.488253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>article81</td>\n",
       "      <td>Suspension of proceedings</td>\n",
       "      <td>Where those proceedings are pending at first i...</td>\n",
       "      <td>144</td>\n",
       "      <td>51</td>\n",
       "      <td>[0.016459905, 0.02905598, 0.016495313, -0.0320...</td>\n",
       "      <td>0.485155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>article73</td>\n",
       "      <td>Chair</td>\n",
       "      <td>The term of office of the Chair and of the dep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.018717434, 0.05230803, 0.0047608837, -0.004...</td>\n",
       "      <td>0.479319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>article75</td>\n",
       "      <td>Secretariat</td>\n",
       "      <td>The secretariat shall provide analytical, admi...</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.036584362, 0.042329982, 0.016415294, 0.0004...</td>\n",
       "      <td>0.477369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>article74</td>\n",
       "      <td>Tasks of the Chair</td>\n",
       "      <td>The Chair shall have the following tasks: to c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.001810194, 0.07275854, 0.0057692835, -0.01...</td>\n",
       "      <td>0.459880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>663 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                      article_title  \\\n",
       "586  article77  Right to lodge a complaint with a supervisory ...   \n",
       "164  article22  Automated individual decision-making, includin...   \n",
       "588  article78  Right to an effective judicial remedy against ...   \n",
       "130  article15                Right of access by the data subject   \n",
       "366  article47                            Binding corporate rules   \n",
       "..         ...                                                ...   \n",
       "31    article4                                        Definitions   \n",
       "598  article81                          Suspension of proceedings   \n",
       "567  article73                                              Chair   \n",
       "576  article75                                        Secretariat   \n",
       "568  article74                                 Tasks of the Chair   \n",
       "\n",
       "                                          article_text article_recitals  \\\n",
       "586  Without prejudice to any other administrative ...              141   \n",
       "164  The data subject shall have the right not to b...            71,72   \n",
       "588  Without prejudice to any other administrative ...              143   \n",
       "130  The data subject shall have the right to obtai...            63,64   \n",
       "366  The binding corporate rules shall specify at l...              110   \n",
       "..                                                 ...              ...   \n",
       "31   'group of undertakings' means a controlling un...               37   \n",
       "598  Where those proceedings are pending at first i...              144   \n",
       "567  The term of office of the Chair and of the dep...              NaN   \n",
       "576  The secretariat shall provide analytical, admi...              140   \n",
       "568  The Chair shall have the following tasks: to c...              NaN   \n",
       "\n",
       "     article_tokens                            article_text_embeddings  \\\n",
       "586              70  [-0.04318639, 0.009823787, 0.0013123561, -0.02...   \n",
       "164              39  [-0.04324376, 0.015624178, 0.016327191, -0.046...   \n",
       "588              40  [-0.045312826, -0.0052126944, 0.026995184, -0....   \n",
       "130              58  [-0.047044102, 0.01906889, 0.0070038955, -0.04...   \n",
       "366              98  [-0.04559353, 0.005038787, 0.028027346, -0.033...   \n",
       "..              ...                                                ...   \n",
       "31               18  [-0.026804209, 0.029797085, 0.0009110155, -0.0...   \n",
       "598              51  [0.016459905, 0.02905598, 0.016495313, -0.0320...   \n",
       "567              21  [0.018717434, 0.05230803, 0.0047608837, -0.004...   \n",
       "576              15  [0.036584362, 0.042329982, 0.016415294, 0.0004...   \n",
       "568              21  [-0.001810194, 0.07275854, 0.0057692835, -0.01...   \n",
       "\n",
       "     distance  \n",
       "586  0.760135  \n",
       "164  0.746726  \n",
       "588  0.735505  \n",
       "130  0.733498  \n",
       "366  0.725485  \n",
       "..        ...  \n",
       "31   0.488253  \n",
       "598  0.485155  \n",
       "567  0.479319  \n",
       "576  0.477369  \n",
       "568  0.459880  \n",
       "\n",
       "[663 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sort_values(['distance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_recitals</th>\n",
       "      <th>article_tokens</th>\n",
       "      <th>article_text_embeddings</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>68</td>\n",
       "      <td>[-0.032365043, -0.008397134, 0.0020770333, -0....</td>\n",
       "      <td>0.803580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>158</td>\n",
       "      <td>[-0.033225175, -0.0029193629, -0.0044079283, -...</td>\n",
       "      <td>0.805873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>89</td>\n",
       "      <td>[-0.0455578, -0.013683858, 0.0030171564, -0.02...</td>\n",
       "      <td>0.797698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>56</td>\n",
       "      <td>[-0.042438716, -0.00021942731, -0.0029840148, ...</td>\n",
       "      <td>0.796488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>73</td>\n",
       "      <td>[-0.03386438, -0.0027421627, 0.002576739, -0.0...</td>\n",
       "      <td>0.801940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>The data subject shall have the right to obtai...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>71</td>\n",
       "      <td>[-0.05192303, -0.0018970313, -0.013146247, -0....</td>\n",
       "      <td>0.788213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Where the controller has made the personal dat...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>77</td>\n",
       "      <td>[-0.039192215, 0.01568776, -0.027002933, -0.03...</td>\n",
       "      <td>0.778074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Right to erasure ('right to be forgotten') sha...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>32</td>\n",
       "      <td>[-0.064188726, -0.017257614, -0.035147376, -0....</td>\n",
       "      <td>0.725918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Right to erasure ('right to be forgotten') sha...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>67</td>\n",
       "      <td>[-0.04173252, 0.0028624088, -0.00333421, -0.01...</td>\n",
       "      <td>0.739766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Right to erasure ('right to be forgotten') sha...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>134</td>\n",
       "      <td>[-0.028719774, 0.004937607, -0.025912542, -0.0...</td>\n",
       "      <td>0.704216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Right to erasure ('right to be forgotten') sha...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>89</td>\n",
       "      <td>[-0.036513474, -0.027594121, -0.01371236, -0.0...</td>\n",
       "      <td>0.722026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>article17</td>\n",
       "      <td>Right to erasure ('right to be forgotten')</td>\n",
       "      <td>Right to erasure ('right to be forgotten') sha...</td>\n",
       "      <td>65,66</td>\n",
       "      <td>32</td>\n",
       "      <td>[-0.031142479, -0.020715242, -0.012883531, -0....</td>\n",
       "      <td>0.729612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                               article_title  \\\n",
       "136  article17  Right to erasure ('right to be forgotten')   \n",
       "137  article17  Right to erasure ('right to be forgotten')   \n",
       "138  article17  Right to erasure ('right to be forgotten')   \n",
       "139  article17  Right to erasure ('right to be forgotten')   \n",
       "140  article17  Right to erasure ('right to be forgotten')   \n",
       "141  article17  Right to erasure ('right to be forgotten')   \n",
       "142  article17  Right to erasure ('right to be forgotten')   \n",
       "143  article17  Right to erasure ('right to be forgotten')   \n",
       "144  article17  Right to erasure ('right to be forgotten')   \n",
       "145  article17  Right to erasure ('right to be forgotten')   \n",
       "146  article17  Right to erasure ('right to be forgotten')   \n",
       "147  article17  Right to erasure ('right to be forgotten')   \n",
       "\n",
       "                                          article_text article_recitals  \\\n",
       "136  The data subject shall have the right to obtai...            65,66   \n",
       "137  The data subject shall have the right to obtai...            65,66   \n",
       "138  The data subject shall have the right to obtai...            65,66   \n",
       "139  The data subject shall have the right to obtai...            65,66   \n",
       "140  The data subject shall have the right to obtai...            65,66   \n",
       "141  The data subject shall have the right to obtai...            65,66   \n",
       "142  Where the controller has made the personal dat...            65,66   \n",
       "143  Right to erasure ('right to be forgotten') sha...            65,66   \n",
       "144  Right to erasure ('right to be forgotten') sha...            65,66   \n",
       "145  Right to erasure ('right to be forgotten') sha...            65,66   \n",
       "146  Right to erasure ('right to be forgotten') sha...            65,66   \n",
       "147  Right to erasure ('right to be forgotten') sha...            65,66   \n",
       "\n",
       "     article_tokens                            article_text_embeddings  \\\n",
       "136              68  [-0.032365043, -0.008397134, 0.0020770333, -0....   \n",
       "137             158  [-0.033225175, -0.0029193629, -0.0044079283, -...   \n",
       "138              89  [-0.0455578, -0.013683858, 0.0030171564, -0.02...   \n",
       "139              56  [-0.042438716, -0.00021942731, -0.0029840148, ...   \n",
       "140              73  [-0.03386438, -0.0027421627, 0.002576739, -0.0...   \n",
       "141              71  [-0.05192303, -0.0018970313, -0.013146247, -0....   \n",
       "142              77  [-0.039192215, 0.01568776, -0.027002933, -0.03...   \n",
       "143              32  [-0.064188726, -0.017257614, -0.035147376, -0....   \n",
       "144              67  [-0.04173252, 0.0028624088, -0.00333421, -0.01...   \n",
       "145             134  [-0.028719774, 0.004937607, -0.025912542, -0.0...   \n",
       "146              89  [-0.036513474, -0.027594121, -0.01371236, -0.0...   \n",
       "147              32  [-0.031142479, -0.020715242, -0.012883531, -0....   \n",
       "\n",
       "     distance  \n",
       "136  0.803580  \n",
       "137  0.805873  \n",
       "138  0.797698  \n",
       "139  0.796488  \n",
       "140  0.801940  \n",
       "141  0.788213  \n",
       "142  0.778074  \n",
       "143  0.725918  \n",
       "144  0.739766  \n",
       "145  0.704216  \n",
       "146  0.722026  \n",
       "147  0.729612  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.loc[x[\"article_title\"] == \"Right to erasure ('right to be forgotten')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[\"article_title\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet \\\n",
    "    \"google-cloud-aiplatform[langchain,reasoningengine]\" \\\n",
    "    cloudpickle==3.0.0 \\\n",
    "    pydantic==2.7.4 \\\n",
    "    langchain-google-community \\\n",
    "    google-cloud-discoveryengine \\\n",
    "    google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_storage_bucket=\"vertex-ai-hack\"\n",
    "google_storage_bucket_link=\"gs://{}\".format(google_storage_bucket)\n",
    "data_bucket=\"{}/data/\".format(google_storage_bucket_link)\n",
    "project_id=\"hackhathon-438922\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines, rag\n",
    "from vertexai.preview.generative_models import GenerativeModel, Tool\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('./keys/hackhathon-438922-0a5870e658d5.json')\n",
    "\n",
    "vertexai.init(\n",
    "    project=project_id,\n",
    "    location=\"us-central1\",\n",
    "    staging_bucket=\"gs://{}\".format(google_storage_bucket),\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = \"eu_ai_act\"\n",
    "paths = [data_bucket]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_config = rag.EmbeddingModelConfig(\n",
    "    publisher_model=\"publishers/google/models/text-embedding-004\"\n",
    ")\n",
    "rag_corpus = rag.create_corpus(\n",
    "    display_name=display_name,\n",
    "    embedding_model_config=embedding_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RagCorpus(name='projects/617378578625/locations/us-central1/ragCorpora/2305843009213693952', display_name='eu_ai_act', description='', embedding_model_config=EmbeddingModelConfig(publisher_model='projects/hackhathon-438922/locations/us-central1/publishers/google/models/text-embedding-004', endpoint=None, model=None, model_version_id=None), vector_db=RagManagedDb())"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imported_rag_files_count: 1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.import_files(\n",
    "    rag_corpus.name,\n",
    "    paths,\n",
    "    chunk_size=512,  # Optional\n",
    "    chunk_overlap=100,  # Optional\n",
    "    max_embedding_requests_per_min=900,  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag.retrieval_query(\n",
    "    rag_resources=[\n",
    "        rag.RagResource(\n",
    "            rag_corpus=rag_corpus.name,\n",
    "            # Optional: supply IDs from `rag.list_files()`.\n",
    "            # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "        )\n",
    "    ],\n",
    "    text=\"Tell me about the EU AI act article 17\",\n",
    "    similarity_top_k=10,  # Optional\n",
    "    vector_distance_threshold=0.7,  # Optional\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client(project=project_id, credentials=credentials)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "\n",
    "    blob.upload_from_filename(source_file_name, if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/AI_ACT_2024.pdf uploaded to AI_ACT_2024.pdf.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(google_storage_bucket, './data/AI_ACT_2024.pdf', 'AI_ACT_2024.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemini-1.5-flash-001\"\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "model_kwargs = {\n",
    "    # temperature (float): The sampling temperature controls the degree of\n",
    "    # randomness in token selection.\n",
    "    \"temperature\": 0,\n",
    "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
    "    # text output from one prompt.\n",
    "    \"max_output_tokens\": 8192,\n",
    "    # top_p (float): Tokens are selected from most probable to least until\n",
    "    # the sum of their probabilities equals the top-p value.\n",
    "    \"top_p\": 0.95,\n",
    "    # top_k (int): The next token is selected from among the top-k most\n",
    "    # probable tokens. This is not supported by all model versions. See\n",
    "    # https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-understanding#valid_parameter_values\n",
    "    # for details.\n",
    "    \"top_k\": None,\n",
    "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
    "    # settings to use for generating content.\n",
    "    # (you must create your safety settings using the previous step first).\n",
    "    \"safety_settings\": safety_settings,\n",
    "    \"credentials\": credentials\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=model,                # Required.\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "response = agent.query(input=\"Tell me about the EU AI act article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about the EU AI act article 17',\n",
       " 'output': \"## EU AI Act Article 17: High-Risk AI Systems and Conformity Assessment\\n\\nArticle 17 of the EU AI Act focuses on **high-risk AI systems** and the **conformity assessment** process they must undergo. This article is crucial for ensuring that these systems are safe, reliable, and comply with the Act's requirements.\\n\\nHere's a breakdown of key points:\\n\\n**1. Scope:**\\n\\n* Article 17 applies to **all high-risk AI systems** as defined in Annex III of the Act. This includes systems used in critical areas like healthcare, transportation, and law enforcement.\\n* It covers the **entire lifecycle** of the system, from design and development to deployment and post-market monitoring.\\n\\n**2. Conformity Assessment:**\\n\\n* **Providers** of high-risk AI systems must undergo a **conformity assessment** to demonstrate compliance with the Act's requirements.\\n* This assessment can be conducted by **independent conformity assessment bodies** (CABs) accredited by national authorities.\\n* The assessment process involves **documentation review, testing, and evaluation** of the system's design, development, and operation.\\n\\n**3. Conformity Assessment Procedures:**\\n\\n* Article 17 outlines **different procedures** for conformity assessment depending on the complexity and risk level of the AI system.\\n* These procedures can include:\\n    * **Internal control:** The provider conducts the assessment themselves.\\n    * **Module A:** The provider involves a CAB for specific aspects of the assessment.\\n    * **Module B:** The provider involves a CAB for the entire assessment process.\\n    * **Module C:** The provider involves a CAB for the initial assessment and ongoing monitoring.\\n\\n**4. Conformity Assessment Body (CAB):**\\n\\n* CABs are **independent organizations** accredited by national authorities to conduct conformity assessments.\\n* They must be **competent and impartial** and adhere to strict ethical and professional standards.\\n* Their role is to **verify** that the AI system meets the requirements of the Act and to issue a **conformity assessment certificate** if successful.\\n\\n**5. Post-Market Monitoring:**\\n\\n* Article 17 also requires **post-market monitoring** of high-risk AI systems.\\n* This involves **collecting data** on the system's performance and identifying any potential risks or issues.\\n* Providers must **report any serious incidents** to the relevant authorities and take appropriate corrective actions.\\n\\n**6. Penalties:**\\n\\n* Failure to comply with Article 17 can result in **penalties** for providers, including fines and even the withdrawal of the system from the market.\\n\\n**In summary, Article 17 of the EU AI Act establishes a robust framework for ensuring the safety and reliability of high-risk AI systems. It requires providers to undergo a rigorous conformity assessment process and to continuously monitor their systems for potential risks. This article is essential for building trust in AI and promoting its responsible development and deployment.**\\n\"}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF document.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF document.\n",
    "    \"\"\"\n",
    "    pdf_file = open(file_path, 'rb')\n",
    "    text = []\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        pages = pdf_reader.pages\n",
    "        temp_text = ''\n",
    "        for i, page_obj in enumerate(pages):\n",
    "            if (num_tokens_from_string(temp_text) > 8150):\n",
    "                text.append(temp_text)\n",
    "                temp_text=''\n",
    "            temp_text += page_obj.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_path = './data/AI_ACT_2024.pdf'\n",
    "extracted_text_list = parse_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=model,                # Required.\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
     ]
    }
   ],
   "source": [
    "refined_text = []\n",
    "for extracted_text in extracted_text_list:\n",
    "    prompt = \"Repair the content of the text below. Make sure to not add any additional text other than what is already there as this would adulterate the content of the page. Only fix spacing and line issues. Do not hallucinate words into the content.\\n\\n {}\".format(extracted_text)\n",
    "    response = agent.query(input=prompt)\n",
    "    refined_text.append(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = ''\n",
    "for text in refined_text:\n",
    "    output_text += \"{}\\n\\n\".format(text)\n",
    "\n",
    "with open('file.txt', 'w') as f:\n",
    "    f.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = num_tokens_from_string(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140933\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file.txt', 'w') as f:\n",
    "    f.write(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_label(str):\n",
    "    idx = str.find(']')\n",
    "    return (str[1:idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_content(start, str):\n",
    "    end_idx = str.find('[', start)\n",
    "    return str[start+1:end_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPTER = 'chapter'\n",
    "CHAPTER_TITLE = 'chapter_title'\n",
    "ARTICLE = 'article'\n",
    "ARTICLE_TITLE = 'article_title'\n",
    "ARTICLE_TEXT = 'article_text'\n",
    "SECTION = 'section'\n",
    "SECTION_TITLE = 'section_title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fields_regulations(chapters, sections, articles):\n",
    "    def get_details_from_regulations(f):\n",
    "        chapter = None\n",
    "        section = None\n",
    "        article = None\n",
    "        for line in f.readlines():\n",
    "            (tag, start_idx) = get_tag_label(line)\n",
    "            content = get_tag_content(start_idx, line)\n",
    "            if (tag == CHAPTER):\n",
    "                if(section != None):\n",
    "                    sections.append(section)\n",
    "                if (article != None):\n",
    "                    articles.append(article)\n",
    "                if(chapter != None):\n",
    "                    chapters.append(chapter)\n",
    "                    section = None\n",
    "                    article = None\n",
    "                chapter = {\n",
    "                    \"chapter_number\": content[8:],\n",
    "                }\n",
    "            if (tag == CHAPTER_TITLE):\n",
    "                chapter[\"chapter_title\"] = content\n",
    "            if (tag == SECTION):\n",
    "                if (article != None):\n",
    "                    articles.append(article)\n",
    "                if(section != None):\n",
    "                    article = None\n",
    "                    sections.append(section)\n",
    "                section = {\n",
    "                    \"chapter_number\": chapter[\"chapter_number\"],\n",
    "                    \"section_number\": content[8:],\n",
    "                }\n",
    "            if (tag == SECTION_TITLE):\n",
    "                section[\"section_title\"] = content\n",
    "            if (tag == ARTICLE):\n",
    "                if(article != None):\n",
    "                    articles.append(article)\n",
    "                article = {\n",
    "                    \"article_number\": content[8:],\n",
    "                    \"section_number\": section[\"section_number\"] if section != None else None,\n",
    "                    \"chapter_number\": chapter[\"chapter_number\"] if chapter != None else None,\n",
    "                }\n",
    "            if (tag == ARTICLE_TITLE):\n",
    "                article['article_title'] = content\n",
    "            if (tag == ARTICLE_TEXT):\n",
    "                article['article_text'] = content\n",
    "    return get_details_from_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fields_annexes(articles):\n",
    "    def get_data_from_annex(f):\n",
    "        article = None\n",
    "        for line in f.readlines():\n",
    "            (tag, start_idx) = get_tag_label(line)\n",
    "            content = get_tag_content(start_idx, line)\n",
    "            if (tag == ARTICLE):\n",
    "                if(article != None):\n",
    "                    articles.append(article)\n",
    "                article = {\n",
    "                    \"article_number\": content[6:],\n",
    "                }\n",
    "            if (tag == ARTICLE_TITLE):\n",
    "                article['article_title'] = content\n",
    "            if (tag == ARTICLE_TEXT):\n",
    "                article['article_text'] = content\n",
    "    return get_data_from_annex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fields_references(references):\n",
    "    def get_data_from_references(f):\n",
    "        for line in f.readlines():\n",
    "            (tag, start_idx) = get_tag_label(line)\n",
    "            content = get_tag_content(start_idx, line)\n",
    "            references.append({\n",
    "                \"reference_number\": tag,\n",
    "                \"reference_text\": content\n",
    "            })\n",
    "    return get_data_from_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fields_guides(guides):\n",
    "    def get_data_from_guides(f):\n",
    "        for line in f.readlines():\n",
    "            (tag, start_idx) = get_tag_label(line)\n",
    "            content = get_tag_content(start_idx, line)\n",
    "            guides.append({\n",
    "                \"id\": tag,\n",
    "                \"text\": content\n",
    "            })\n",
    "    return get_data_from_guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array_from_file( file_path, get_details ):\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        get_details(f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = []\n",
    "sections = []\n",
    "articles = []\n",
    "get_details_from_regulations = get_data_fields_regulations(chapters, sections, articles)\n",
    "create_array_from_file('./regulation.txt', get_details_from_regulations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "annex_articles = []\n",
    "get_details_from_annex = get_data_fields_annexes(articles=annex_articles)\n",
    "create_array_from_file('./annex.txt', get_details_from_annex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "get_details_from_reference = get_data_fields_references(references)\n",
    "create_array_from_file('./references.txt', get_details_from_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "guides = []\n",
    "get_data_guides = get_data_fields_guides(guides)\n",
    "create_array_from_file('./guide.txt', get_data_guides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df = pd.DataFrame(chapters)\n",
    "section_df = pd.DataFrame(sections)\n",
    "article_df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "annex_articles_df = pd.DataFrame(annex_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_df = pd.DataFrame(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df = pd.DataFrame(guides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df.to_csv('ai_act_chapters.csv', index=False)\n",
    "section_df.to_csv('ai_act_sections.csv', index=False)\n",
    "article_df.to_csv('ai_act_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "annex_articles_df.to_csv('ai_act_annex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_df.to_csv('ai_act_references.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df.to_csv('ai_act_guide.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chapters_sections = pd.merge(chapter_df, section_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chapter_sections_articles = pd.merge(merge_chapters_sections, article_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter_number</th>\n",
       "      <th>chapter_title</th>\n",
       "      <th>section_number</th>\n",
       "      <th>section_title</th>\n",
       "      <th>article_number</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject matter</td>\n",
       "      <td>1. The purpose of this Regulation is to improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Scope</td>\n",
       "      <td>1. This Regulation applies to:(a)providers pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>For the purposes of this Regulation, the follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>AI literacy</td>\n",
       "      <td>Providers and deployers of AI systems shall ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>II</td>\n",
       "      <td>PROHIBITED AI PRACTICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Prohibited AI practices</td>\n",
       "      <td>1. The following AI practices shall be prohibi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chapter_number            chapter_title section_number section_title  \\\n",
       "0              I       GENERAL PROVISIONS            NaN           NaN   \n",
       "1              I       GENERAL PROVISIONS            NaN           NaN   \n",
       "2              I       GENERAL PROVISIONS            NaN           NaN   \n",
       "3              I       GENERAL PROVISIONS            NaN           NaN   \n",
       "4             II  PROHIBITED AI PRACTICES            NaN           NaN   \n",
       "\n",
       "  article_number            article_title  \\\n",
       "0              1           Subject matter   \n",
       "1              2                    Scope   \n",
       "2              3              Definitions   \n",
       "3              4              AI literacy   \n",
       "4              5  Prohibited AI practices   \n",
       "\n",
       "                                        article_text  \n",
       "0  1. The purpose of this Regulation is to improv...  \n",
       "1  1. This Regulation applies to:(a)providers pla...  \n",
       "2  For the purposes of this Regulation, the follo...  \n",
       "3  Providers and deployers of AI systems shall ta...  \n",
       "4  1. The following AI practices shall be prohibi...  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_chapter_sections_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chapter_sections_articles.to_csv('ai_act_regulations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
